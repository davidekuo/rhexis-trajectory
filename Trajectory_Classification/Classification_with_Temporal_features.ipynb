{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification_with_Temporal_features.ipynb","provenance":[],"collapsed_sections":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MsL1KUUCSzlf"},"outputs":[],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install wandb -qqq\n","import wandb\n","\n","# Login to wandb\n","wandb.login()\n","use_wandb = True"],"metadata":{"id":"XTiH699d9LG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA_LOC = \"/content/drive/MyDrive/Rhexis/datasets/test_pulls\"\n","REPO_LOC = \"/content/drive/MyDrive/Projects/rhexis-trajectory\""],"metadata":{"id":"-lZiH4M0vpO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import sys\n","sys.path.insert(0,f\"{REPO_LOC}/Trajectory_Classification\")\n","from utils import *\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"b7isWtABS9py"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load data"],"metadata":{"id":"Xpi5di5SMggx"}},{"cell_type":"code","source":["names, path_dfs, labels, sizes = load_all_pulls(DATA_LOC)"],"metadata":{"id":"l3fmHKivfuAV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_dfs[0]"],"metadata":{"id":"LHodCbV0M0wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = np.stack([featurize_pull(pull) for pull in path_dfs], axis=0)\n","data[0]"],"metadata":{"id":"PHc9mq7B7giM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X, y = np.stack([featurize_pull(pull, 15) for pull in path_dfs], axis=0), np.array(labels)\n","X[0]"],"metadata":{"id":"ms2IyDt8PguC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedShuffleSplit\n","\n","# Keep deterministic\n","np.random.seed(13)\n","sss = StratifiedShuffleSplit(1, test_size=.2)\n","train_ind, test_ind = next(sss.split(X, y))\n","X_train, X_test = X[train_ind], X[test_ind]\n","y_train, y_test = y[train_ind], y[test_ind]\n","# Print to check class balance\n","y_train, y_test"],"metadata":{"id":"vi1v_0fBPaAB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","from sklearn import preprocessing\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","NUM_ANGLE_BINS = list(range(3, 30))\n","for num_bins in NUM_ANGLE_BINS:\n","  wandb.init(\n","    # Set the project where this run will be logged\n","    project=\"rhexis-classification-temp-logreg\",\n","    entity=\"rhexis-trajectory\",\n","    # We pass a run name (otherwise it'll be randomly assigned, like sunshine-lollypop-10)\n","    name=\"temporal_classification\",\n","    # Track hyperparameters and run metadata\n","    config={\n","      \"num_angle_bins\":num_bins,\n","    })\n","\n","  X, y = np.stack([featurize_pull(pull, num_bins) for pull in path_dfs], axis=0), np.array(labels)\n","  np.random.seed(13)\n","  sss = StratifiedShuffleSplit(1, test_size=.2)\n","  train_ind, test_ind = next(sss.split(X, y))\n","  X_train, X_test = X[train_ind], X[test_ind]\n","  y_train, y_test = y[train_ind], y[test_ind]\n","  clf = LogisticRegression(random_state=0, multi_class=\"multinomial\", max_iter=1000)\n","  pipe = make_pipeline(StandardScaler(), clf)\n","  # print(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy'))\n","  # print(cross_val_score(pipe, X_train, y_train, cv=4, scoring='accuracy'))\n","  pipe.fit(X_train, y_train)\n","  y_pred = pipe.predict(X_test)\n","  wandb.sklearn.plot_learning_curve(clf, X_train, y_train)\n","  wandb.finish()"],"metadata":{"id":"lAHzymSiPpR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","\n","clf = QuadraticDiscriminantAnalysis()\n","pipe = make_pipeline(StandardScaler(), clf)\n","cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy')"],"metadata":{"id":"sFG_snlTSTp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.cluster import MiniBatchKMeans\n","from sklearn.metrics import accuracy_score\n","\n","BATCH_SIZE = 3\n","kmeans = MiniBatchKMeans(n_clusters=3,\n","                          random_state=0,\n","                          batch_size=BATCH_SIZE)\n","\n","pipe = make_pipeline(StandardScaler(), kmeans)\n","for i in range(0, len(X_train), BATCH_SIZE):\n","  pipe.partial_fit(X_train[i:i+BATCH_SIZE])\n","\n","y_pred = kmeans.predict(X_test)\n","# accuracy_score(y_test, y_pred)"],"metadata":{"id":"6cIhBLK6XAXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","\n","clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n","                     hidden_layer_sizes=(50, 25), random_state=1)\n","pipe = make_pipeline(StandardScaler(),\n","                     clf)\n","pipe.fit(X_train, y_train)\n","cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy')\n"],"metadata":{"id":"0qphQ0thyLyT"},"execution_count":null,"outputs":[]}]}
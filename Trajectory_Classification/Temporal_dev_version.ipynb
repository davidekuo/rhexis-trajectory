{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Temporal_dev_version.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "private_outputs": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsL1KUUCSzlf"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "\n",
    "# Login to wandb\n",
    "wandb.login()\n",
    "use_wandb = True"
   ],
   "metadata": {
    "id": "XTiH699d9LG2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_LOC = \"/content/drive/MyDrive/Rhexis/datasets/test_pulls\"\n",
    "REPO_LOC = \"/content/drive/MyDrive/Stanford/rhexis-trajectory\""
   ],
   "metadata": {
    "id": "-lZiH4M0vpO3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, f\"{REPO_LOC}/Trajectory_Classification\")\n",
    "from trajectory_smoothing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "id": "b7isWtABS9py"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "id": "Xpi5di5SMggx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "names, path_dfs, labels, sizes = load_all_pulls(DATA_LOC)"
   ],
   "metadata": {
    "id": "l3fmHKivfuAV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "path_dfs[0]"
   ],
   "metadata": {
    "id": "LHodCbV0M0wy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = np.stack([featurize_pull(pull) for pull in path_dfs], axis=0)\n",
    "data[0]"
   ],
   "metadata": {
    "id": "PHc9mq7B7giM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = np.stack([featurize_pull(pull, 15) for pull in path_dfs], axis=0), np.array(\n",
    "    labels\n",
    ")\n",
    "X[0]"
   ],
   "metadata": {
    "id": "ms2IyDt8PguC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Keep deterministic\n",
    "np.random.seed(13)\n",
    "sss = StratifiedShuffleSplit(1, test_size=0.2)\n",
    "train_ind, test_ind = next(sss.split(X, y))\n",
    "X_train, X_test = X[train_ind], X[test_ind]\n",
    "y_train, y_test = y[train_ind], y[test_ind]\n",
    "# Print to check class balance\n",
    "y_train, y_test"
   ],
   "metadata": {
    "id": "vi1v_0fBPaAB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "NUM_ANGLE_BINS = list(range(3, 30))\n",
    "for num_bins in NUM_ANGLE_BINS:\n",
    "    # wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    # project=\"rhexis-classification-temp-logreg\",\n",
    "    # entity=\"rhexis-trajectory\",\n",
    "    # We pass a run name (otherwise it'll be randomly assigned, like sunshine-lollypop-10)\n",
    "    # name=\"temporal_classification\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    # config={\n",
    "    #  \"num_angle_bins\":num_bins,\n",
    "    # })\n",
    "\n",
    "    X, y = np.stack(\n",
    "        [featurize_pull(pull, num_bins) for pull in path_dfs], axis=0\n",
    "    ), np.array(labels)\n",
    "    np.random.seed(13)\n",
    "    sss = StratifiedShuffleSplit(1, test_size=0.2)\n",
    "    train_ind, test_ind = next(sss.split(X, y))\n",
    "    X_train, X_test = X[train_ind], X[test_ind]\n",
    "    y_train, y_test = y[train_ind], y[test_ind]\n",
    "    clf = LogisticRegression(random_state=0, multi_class=\"multinomial\", max_iter=1000)\n",
    "    pipe = make_pipeline(StandardScaler(), clf)\n",
    "    # print(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy'))\n",
    "    # print(cross_val_score(pipe, X_train, y_train, cv=4, scoring='accuracy'))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    wandb.sklearn.plot_learning_curve(clf, X_train, y_train)\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "id": "lAHzymSiPpR6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "pipe = make_pipeline(StandardScaler(), clf)\n",
    "cross_val_score(pipe, X_train, y_train, cv=5, scoring=\"accuracy\")"
   ],
   "metadata": {
    "id": "sFG_snlTSTp_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "kmeans = MiniBatchKMeans(n_clusters=3, random_state=0, batch_size=BATCH_SIZE)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), kmeans)\n",
    "for i in range(0, len(X_train), BATCH_SIZE):\n",
    "    pipe.partial_fit(X_train[i : i + BATCH_SIZE])\n",
    "\n",
    "y_pred = kmeans.predict(X_test)\n",
    "# accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "id": "6cIhBLK6XAXU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    solver=\"lbfgs\", alpha=1e-5, hidden_layer_sizes=(50, 25), random_state=1\n",
    ")\n",
    "pipe = make_pipeline(StandardScaler(), clf)\n",
    "pipe.fit(X_train, y_train)\n",
    "cross_val_score(pipe, X_train, y_train, cv=5, scoring=\"accuracy\")"
   ],
   "metadata": {
    "id": "0qphQ0thyLyT"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}